{
  "hash": "1e2569b74ff5c8dfc109c7c2a4ef2cfa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Blog 2: Data Loading, Cleaning, and Diagnostic Plots\"\ndescription:  |\n  Description of datasets found.\nauthor: \"TEAMATE\"\ndate: \"2025-03-17\"\ndraft: FALSE\n---\n\n\n\n## Data Background\n\nThis project uses data from the study *\"Systemic Discrimination Among Large U.S. Employers\"* by Patrick Kline, Evan K. Rose, and Christopher Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\n- **Objective:** To detect whether disparate treatment in hiring—particularly based on race, gender, and age—is concentrated within specific companies.\n- **Design:** A targeted randomized control trial where fictitious applications (varying by race, gender, and other resume characteristics) were submitted to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\n- **Scale:** Over 84,000 applications were sent, enabling both firm-level and industry-level analysis of callback rates.\n- **Context:** The data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis background provides important context on both the experimental design and the intended use of the data, highlighting potential challenges such as sample bias and variability across firms.\n\nIn this post, I describe the initial steps for loading and cleaning the dataset. I begin by reading in the cleaned data from an RDS file. The dataset contains various variables, including `age_at_sub`, `month`, `year`, and `state`, which I will explore to understand data quality and identify potential issues. Below is some sample R code I developed to generate diagnostic plots. I create a histogram to visualize the distribution of submissions throughout the months, faceted by year. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\ndata <- readRDS(\"dataset/cleaned_data.rds\")\n```\n:::\n\n\n\n# Diagnostic Plots\n## Check distribution of submission month throughout years\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = month)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  \n  scale_x_continuous(\n    breaks = 1:12,\n    labels = month.abb\n  ) +\n  labs(\n    title = \"Distribution of Months\",\n    x = \"Month\",\n    y = \"Count\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45)) +\n  facet_grid(~year)\n```\n\n::: {.cell-output-display}\n![](blog-2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThis plot shows  sparse activity in early 2019, with submissions only appearing in a couple of months. In 2020, there is a notable increase, particularly in the latter half of the year. The highest volume of submissions occurs in early 2021, creating a distinct peak in the data. Overall, the distribution suggests that most of the data collection took place from late 2020 into the first months of 2021.\n",
    "supporting": [
      "blog-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}