[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the original file data.qmd. This page details our data sources, the cleaning process, and provides initial diagnostic plots. For this project, we work with data from the landmark study Systemic Discrimination Among Large U.S. Employers (Kline, Rose, and Walters, 2022). The data was originally collected through a fake resume experiment to investigate patterns of hiring discrimination in large US employers, making it highly relevant to both current social justice issues and policy enforcement efforts."
  },
  {
    "objectID": "data.html#data-sources-and-rationale",
    "href": "data.html#data-sources-and-rationale",
    "title": "Data",
    "section": "Data Sources and Rationale",
    "text": "Data Sources and Rationale\n\nExperimental, Main Dataset\n\nSource: The dataset is available on Harvard Dataverse and was published alongside the study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù.\nLink to original data source\nPurpose: The data were collected to examine whether hiring discrimination is endemic to particular firms and to quantify the impact of factors such as race, gender, and age on callback rates.\nWhy this Data: We selected this dataset because it not only addresses pressing issues of discrimination and equity but also includes rich information (e.g., date, location, and applicant demographics) that supports extensive exploratory and inferential analysis.\n\n\n\nCensus Population, Demographic Data\n\nSource: The census data was obtained from the United States Census Bureau.\nLink to census data and Link to census data\nPurpose: The census data provides demographic information about the population in each state, which is essential for understanding the the size of the population in each state and how it relates to labor market dynamics.\nWhy this Data: The census data is crucial for contextualizing the experimental data, allowing us to compare relative submission versus the number of applications in the study. This enables us to assess the representativeness of the sample and to explore potential biases in the data."
  },
  {
    "objectID": "data.html#data-files-and-variables",
    "href": "data.html#data-files-and-variables",
    "title": "Data",
    "section": "Data Files and Variables",
    "text": "Data Files and Variables\n\nExperimental Dataset\nThe project focuses on a single dataset that was processed and saved as an RDS file (cleaned_data.rds). Some Key variables include:\n\nage_at_sub: Age of the applicant at the time of submission.\nmonth and year: Date components of when applications were submitted.\nstate: Geographic information about the submission.\nrace: Race of the applicant.\ncb: Binary indicator for whether an applicant received a callback (1 = Yes, 0 = No).\nAdditional variables (e.g., gender, education, etc.) are available and grouped.\n\nFor a detailed account of variable definitions and transformations, please refer to our cleaning script.\n\n\nCensus Dataset\nTo see how we combine the census data with the application data, please refer to our census cleaning script"
  },
  {
    "objectID": "data.html#data-cleaning-process",
    "href": "data.html#data-cleaning-process",
    "title": "Data",
    "section": "Data Cleaning Process",
    "text": "Data Cleaning Process\n\nThe raw data was imported, cleaned, and transformed using R. The cleaning process involved:\n\nRenaming variables and recoding factors for clarity.\nRemoving duplicate and inconsistent entries.\nAggregating multiple data files (if applicable) to produce the final cleaned dataset.\nSaving the cleaned dataset as an RDS file for efficient reloading in analyses.\n\nFor census data and aggregation, we follow the process below:\n\nVariables were renamed and factors recoded for clarity.\nDuplicate and inconsistent entries were eliminated.\nIndividual application records were aggregated to the state level.\nThe state-level application data was merged with census population counts to calculate the proportion of applications relative to state populations."
  },
  {
    "objectID": "data.html#diagnostic-plots",
    "href": "data.html#diagnostic-plots",
    "title": "Data",
    "section": "Diagnostic Plots",
    "text": "Diagnostic Plots\nBelow are some initial diagnostic plots generated from the cleaned dataset.\n\nImporting the Cleaned Data\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(usmap)) # used for plotting US maps\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\nmerged_data &lt;- readRDS(\"dataset/merged_data_state_by_year.rds\")\n\n\n\nCheck for outliers in Age at Submission\n\n\n\n\n\n\n\n\n\nAs defined by the authors, the age is uniformly distributed between 20 and 60. This plot confirms that there are no outliers in the age variable.\n\n\nCheck distribution of submissions throughout years\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of applications by month and year. The data is aggregated by month and year, allowing us to see trends over time. Notably, data from 2020 March to June is missing, likely due to the COVID-19 pandemic. January 2021 shows the distribution mode, with a significant number of applications submitted during that month.\nThis histogram legitimizes the necessity of controlling for a wave of application in our analysis, as these time trends could be correlated with other variables.\n\n\nDistribution of Submissions by State\n\n\n\n\n\n\n\n\n\nIn this plot, we can see that California has the highest number of applications, followed by Texas and Florida. This distribution is important for understanding the geographic representation of our sample and its implications for the analysis.\n\n\nGeographic Distribution of Submissions Versus Population By State\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe above two plots show the geographic distribution of applications and population size across states. The first plot shows the mean population size of each state from 2019 to 2021, while the second plot shows the total number of applications within each state during the same period.\nThe takeaway from these plots is that the relative number of applications across states largely reflects the size of the population in each state. In particular, states in the West, Northeast, and Southeast‚Äîregions known for having larger populations‚Äîconsistently show higher application counts, aligning with the overall demographic distribution across the United States."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nCode Reference:"
  },
  {
    "objectID": "analysis.html#loading-data",
    "href": "analysis.html#loading-data",
    "title": "Analysis",
    "section": "Loading data",
    "text": "Loading data\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\nsuppressPackageStartupMessages(library(lfe))    \nsuppressPackageStartupMessages(library(lmtest))\nsuppressPackageStartupMessages(library(sandwich)) \nsuppressPackageStartupMessages(library(multiwayvcov))\nsuppressPackageStartupMessages(library(here))\nsuppressPackageStartupMessages(library(gtsummary))\nsuppressPackageStartupMessages(library(htmltools))\nsuppressPackageStartupMessages(library(broom))\nsuppressPackageStartupMessages(library(stringr))\n\ndata &lt;- readRDS(here::here(\"dataset/cleaned_data.rds\"))"
  },
  {
    "objectID": "analysis.html#motivation",
    "href": "analysis.html#motivation",
    "title": "Analysis",
    "section": "Motivation",
    "text": "Motivation\nDespite decades of regulatory and legal efforts to eliminate hiring discrimination, numerous field experiments continue to document persistent gaps in employer callback rates by race. In the study by Rose et al.¬†(2022), the large-scale fake resume experiment among Fortune 500 firms in the US enables us to investigate the extent of taste-based discrimination in hiring practices.\nIn a nutshell, the study sends fake resumes with randomly assigned characteristics to entry-level positions among large U.S. employers. This is an example of how a sample of resumes looks like: \n\nNote: sourced from Figure A1: Examples of applicant resumes in the Rose et al.¬†(2022) paper."
  },
  {
    "objectID": "analysis.html#research-questions",
    "href": "analysis.html#research-questions",
    "title": "Analysis",
    "section": "Research Questions",
    "text": "Research Questions\nThere is a famous saying:\n\nCorrelation does not imply causation.\n\nThis is especially true when it comes to the dialogue of racial disparity from a data-driven point of view. In the previous correlation-based analysis, the discrimination gap may have been misspecified due to omitted variable bias (OVB). For instance, instead of taste-based discrimination, labor market outcome inequality may be driven by different levels of educational attainment, work experience, or other factors that are not controlled for.\nThis analysis leverages the powerful experimental data and codes from the Rose et al.¬†(2022) paper to estimate the causal impact of being Black on the probability of receiving a callback.\nThe analysis is based on the following research questions:\n\nDoes tasted-based discrimination cause differential labor market outcomes in the U.S?\n\n\nIf so, how large is the magnitude?\n\n\nIs there evidence of intersectional heterogeneity‚Äîthat is, does the magnitude of the Black callback penalty vary by another trait?\n\n\n\nIf so, how large is the magnitude?\n\n\nDo firm‚Äë or month‚Äëlevel shocks attenuate or amplify measured discrimination?"
  },
  {
    "objectID": "analysis.html#summary-statistics",
    "href": "analysis.html#summary-statistics",
    "title": "Analysis",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll Firms - Black\nN = 9,1411\nAll Firms - White\nN = 9,1341\nBalanced - Black\nN = 32,6651\nBalanced - White\nN = 32,7031\n\n\n\n\nAny contact\n1,972 (22%)\n2,103 (23%)\n7,647 (23%)\n8,380 (26%)\n\n\nAny voicemail contact\n1,246 (14%)\n1,383 (15%)\n5,410 (17%)\n6,052 (19%)\n\n\nAny email contact\n256 (2.8%)\n263 (2.9%)\n1,357 (4.2%)\n1,414 (4.3%)\n\n\nAny text message contact\n470 (5.1%)\n457 (5.0%)\n880 (2.7%)\n914 (2.8%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\nThe first panel (‚ÄúAll Firms‚Äù) shows that Black applicants receive any form of contact in 22 percent of applications versus 23 percent for White applicants‚Äîa modest raw gap. When we restrict to the ‚ÄúBalanced‚Äù sample, the disparity widens: 23 percent versus 26 percent. Similar patterns hold for voicemails (17% vs 19%) and email/text contacts. These descriptive gaps motivate our causal estimation below and suggest that, even with the same pool of job postings, Black applicants face lower call‚Äëback rates across multiple channels."
  },
  {
    "objectID": "analysis.html#descriptive-evidence-by-applicants-first-name",
    "href": "analysis.html#descriptive-evidence-by-applicants-first-name",
    "title": "Analysis",
    "section": "Descriptive Evidence by Applicants First Name",
    "text": "Descriptive Evidence by Applicants First Name\n\n\n\n\n\n\n\n\n\nThis figure shows mean contact rates by applicant first name, organized by race and gender group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names."
  },
  {
    "objectID": "analysis.html#effect-of-taste-based-discrimination-on-contact-rates",
    "href": "analysis.html#effect-of-taste-based-discrimination-on-contact-rates",
    "title": "Analysis",
    "section": "Effect of Taste-Based Discrimination on Contact Rates",
    "text": "Effect of Taste-Based Discrimination on Contact Rates\nDue to the nature of experimental data, we can estimate the causal effect of large employers‚Äô taste-based discrimination on applicant labor market outcomes.\n\nModel Specification\nThe code estimates the causal effect of being Black on the probability of receiving a callback, controlling for a vector of other resume characteristics. Formally, two specifications:\n\nLinear probability model (OLS):\n\n\nwith controls for all sample\nwith controls for a balanced sample\ntwo-way fixed effects for all sample\ntwo-way fixed effects for a balanced sample\n\n\nLogistic regression\n\n\nwith controls for all sample\nwith controls for a balanced sample\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\nCall Back Prob.\n\n\n\nOLS\nlogistic\nOLS\nlogistic\n\n\n\n(1)\n(2)\n(3)\n(4)\n(5)\n(6)\n\n\n\n\n\nBlack\n-0.021***\n-0.020***\n-0.115***\n-0.022***\n-0.022***\n-0.123***\n\n\n\n(0.003)\n(0.003)\n(0.016)\n(0.003)\n(0.003)\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nFemale\n0.0002\n\n0.001\n-0.0002\n\n-0.002\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nOver 40\n-0.006**\n\n-0.033**\n-0.005\n\n-0.027\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\nPolitical club\n-0.002\n\n-0.010\n-0.003\n\n-0.017\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nAcademic club\n0.010\n\n0.052\n0.006\n\n0.028\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nLGBTQ club\n-0.005\n\n-0.029\n-0.00004\n\n-0.001\n\n\n\n(0.005)\n\n(0.030)\n(0.006)\n\n(0.034)\n\n\n\n\n\n\n\n\n\n\n\nSame‚Äëgender pronouns\n-0.014*\n\n-0.077*\n-0.013\n\n-0.068\n\n\n\n(0.007)\n\n(0.041)\n(0.008)\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\nGender‚Äëneutral pronouns\n-0.010\n\n-0.057\n-0.017**\n\n-0.095**\n\n\n\n(0.007)\n\n(0.041)\n(0.009)\n\n(0.048)\n\n\n\n\n\n\n\n\n\n\n\nAssociate degree\n0.001\n\n0.007\n0.003\n\n0.014\n\n\n\n(0.003)\n\n(0.016)\n(0.003)\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample\nAll Firms\nAll Firms\nAll Firms\nBalanced\nBalanced\nBalanced\n\n\nFirm FE\nNo\nYes\nNo\nNo\nYes\nNo\n\n\nMonth FE\nNo\nYes\nNo\nNo\nYes\nNo\n\n\nObservations\n83,643\n83,643\n83,643\n65,368\n65,368\n65,368\n\n\nR2\n0.024\n0.151\n\n0.024\n0.130\n\n\n\nAdjusted R2\n0.024\n0.150\n\n0.024\n0.129\n\n\n\nF Statistic\n126.977*** (df = 16; 83626)\n120.790*** (df = 123; 83519)\n\n101.025*** (df = 16; 65351)\n112.290*** (df = 87; 65280)\n\n\n\n\n\n\nNote:\n*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\nClustered SEs by job\n\n\n\nAcross all specifications, the coefficient on Black is consistently negative and highly significant. In the simplest linear probability model (column 1), being Black reduces the probability of any callback by about 2.1 percentage points (SE=0.3pp). When we add firm and month fixed effects (column 2), the gap narrows only slightly to 2.0 pp, indicating that sorting of Black resumes into ‚Äúeasier‚Äù or ‚Äútougher‚Äù firms/months accounts for very little of the raw disparity. In the balanced‚Äêsample OLS (column 5), the Black penalty is essentially unchanged at 2.2 pp.¬†The corresponding logistic regressions (columns 3 and 6) imply a roughly 11‚Äì12 percent reduction in the odds of callback for Black applicants, again robust to fixed effects and sample restrictions.\nAmong the other resume traits, Over 40 exhibits a modest negative effect in the unrestricted sample (‚Äì0.6 pp) but loses significance in the balanced sample. Gender itself (Female) has no discernible callback penalty or bonus. Signals like political, academic, or LGBTQ club affiliations never reach conventional significance, nor does holding an associate degree. Interestingly, the use of same‚Äëgender pronouns on the r√©sum√© is associated with a small but borderline significant callback penalty in the basic models (‚Äì1.4 pp), and the neutral‚Äëpronoun penalty becomes significant in the balanced OLS (‚Äì1.7 pp). This hints that nontraditional pronoun signaling may carry a slight cost in this context, though the effect sizes are small relative to the race gap.\nThe model fit remains modest: R¬≤ climbs from just 2.4 percent without fixed effects to about 15 percent once we absorb firm‚Äêand‚Äêmonth variation, underscoring that much of the callback decision is driven by idiosyncratic job‚Äêlevel factors and unobserved employer preferences. All standard errors are clustered at the job level, and the F‚Äëstatistics confirm the joint significance of the regressors.\nKey takeaway : Even after controlling for a broad vector of resume characteristics and accounting for firm/month heterogeneity, Black applicants face a persistent 2pp lower callback rate‚Äîroughly a 12 percent relative penalty‚Äîhighlighting taste‚Äëbased discrimination in large‚Äëfirm hiring.\n\n\nVisualization of OLS Estimates\n\n\n\n\n\n\n\n\n\nWe can observe that the coefficient estimates for the Black variable are negative and significant across all samples since the 95% confidence intervals do not include 0. Also, gender-neutral pronoun estimates are significant in the balanced sample."
  },
  {
    "objectID": "analysis.html#heterogeneity-analysis",
    "href": "analysis.html#heterogeneity-analysis",
    "title": "Analysis",
    "section": "Heterogeneity Analysis",
    "text": "Heterogeneity Analysis\nIn this section, we use interaction terms to explore how the effect of being Black on labor market outcomes varies across different characteristics of the resumes.\n\n\n\n\n\n\n\n\n\nAlthough we don‚Äôt find a significant gender penalty in the baseline model, the black-female interaction remains significant across sample restrictions, indicating that Black women experience an extra callback penalty beyond what the additive race and gender effects predict.\nThe interaction term between Black and gender‚Äëneutral pronouns is also significant in the balanced sample. In other words, Black applicants who include gender‚Äëneutral pronouns on their r√©sum√© face an additional callback penalty."
  },
  {
    "objectID": "analysis.html#conclusion",
    "href": "analysis.html#conclusion",
    "title": "Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis leverages a large-scale r√©sum√© audit experiment to estimate the causal effect of race on callback rates at Fortune 500 firms. Across all linear probability and logit specifications‚Äîboth unrestricted and balanced samples‚Äîbeing Black reduces the probability of any form of contact by roughly 2¬†percentage points (‚âà 11‚Äì12 percent relative penalty), a gap that remains unchanged once we absorb firm and month fixed effects.\nPronoun usage carries a small penalty, and in the balanced sample the Black¬†√ó¬†Gender‚ÄëNeutral Pronouns and Black¬†√ó¬†Female interaction are also significant, indicating an extra penalty for Black applicants who signal intersecionality.\n\n\nLimitations\n\nExternal validity: Firms in the Fortune 500 may not reflect smaller or mid‚Äësized employers‚Äô behavior. The generalizability of these results to other sectors or regions is uncertain. Future work could extend this analysis to a broader set of firms, including smaller employers or those in different industries.\nAdditional outcome: Social capital and social networks are important in the hiring process. Future work could explore how race affect social capital accumulation and its impact on hiring outcomes. For example, do Black applicants have fewer connections to employees at the firms they apply to? Do they receive fewer referrals or recommendations from friends or family members?\n\nA new study using LinkedIn: LinkedOut? A Field Experiment on Discrimination in Job Network Formation\n\nMore racial variation: Since this study only covers black-white differences, it would be interesting to see how other racial groups are affected. For example, do Asian applicants face similar or different discrimination patterns compared to Black applicants? Do Hispanic applicants experience different callback rates based on their names or other characteristics?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "All else being equal, will a job applicant with a black-sounding name receive fewer callbacks than a job applicant with a white-sounding name? We leverage a large correspondence experiment dataset to answer this question.\n\nThis comes from the index.qmd file; Blog codes are in the posts directory.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 8: Progress So Far\n\n\n\n\n\nPlans to wrap up the project. \n\n\n\n\n\nApr 30, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 7: Interactive Analysis\n\n\n\n\n\nA self-contained Shiny app. \n\n\n\n\n\nApr 22, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 6: Wrapping Up the Analysis\n\n\n\n\n\nWrapping up original analysis in the paper. \n\n\n\n\n\nApr 16, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 5: Geographic Analysis of Experiment and Census Data\n\n\n\n\n\nLeverage Census data to check the geographical distribution of the experimental design.. \n\n\n\n\n\nApr 7, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 4: Extended Statistical Modeling\n\n\n\n\n\nApply some statistical modeling to our data. \n\n\n\n\n\nMar 31, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 3: Extended Analysis and Equity Considerations\n\n\n\n\n\nPreliminary data exploration and explore the structure of the data. \n\n\n\n\n\nMar 24, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 2: Data Loading, Cleaning, and Diagnostic Plots\n\n\n\n\n\nThis blog shows the background of our data and how we visualize it. \n\n\n\n\n\nMar 17, 2025\n\n\nTEAMATE\n\n\n\n\n\n\n\n\n\n\n\n\nBlog 1: Data Progress\n\n\n\n\n\nDescription of datasets found. \n\n\n\n\n\nFeb 24, 2025\n\n\nTEAMATE\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-02-24-blog-1/blog-1.html",
    "href": "posts/2025-02-24-blog-1/blog-1.html",
    "title": "Blog 1: Data Progress",
    "section": "",
    "text": "Data #1: URL: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HLO4XC\nThe data comes from Kline, Patrick, Evan K. Rose, and Christopher R. Walters, ‚ÄúSystemic Discrimination Among Large U.S. Employers,‚Äù The Quarterly Journal of Economics, vol.¬†137 no. 4, (2022), 1963-2036.https://doi.org/10.1093/qje/qjac024. This dataset, published alongside the article by Kline, Rose, and Walters (2022), examines potential systemic hiring discrimination by large U.S. employers. The data primarily cover hiring outcomes, employer characteristics, and applicant demographic details spanning several years. Data is originally collected by authors. They conducted a randomized control trail (RCT) to identify patterns of potential discrimination, estimating the magnitude of these effects, and understanding whether certain employer or regional characteristics are associated with differential outcomes.\nData #2: URL: https://opportunityinsights.org/data/\nThe dataset described in College-Level Data for 139 Selective American Colleges provides insights into college application and attendance patterns among U.S. students based on parental income. Compiled by linking standardized test-takers (SAT or ACT from 2011, 2013, or 2015) to tax data, this dataset categorizes students into income bins to analyze disparities in college access. It covers 139 selective colleges, including Ivy-Plus institutions, elite private colleges, and flagship public universities. The dataset includes key metrics such as relative application rates, attendance rates, and conditional attendance rates, allowing researchers to examine how income influences higher education opportunities.\nA challenge in working with this dataset is its reliance on estimated values, as noise has been added for privacy reasons, potentially affecting precision. Additionally, while the dataset is rich in application and attendance statistics, it does not include direct measures of student academic performance beyond standardized test scores, limiting deeper analysis of post-admission outcomes.\nData #3 URL: https://www.samhsa.gov/data/data-we-collect/teds-treatment-episode-data-set/datafiles The Treatment Episode Data Set (TEDS), available through the SAMHSA website (TEDS Data Files), provides comprehensive data on individuals entering substance abuse treatment programs across the U.S. It includes over 2 million treatment episodes, with rows representing individual treatment episodes and columns covering demographics, substance use types, treatment modalities, and outcomes. The data is collected through state-administered systems in federally-funded treatment centers, aiming to monitor patterns of substance use, treatment needs, and outcomes. This standardized collection allows for detailed analysis of treatment trends across different regions and populations.\nWhile the dataset is available in multiple formats such as SAS, SPSS, and ASCII, loading and cleaning the data may require addressing missing values, ensuring proper data type conversion, and standardizing categories. A few key questions that can be explored include how treatment outcomes vary by demographics and how substance abuse trends differ across states and over time. Challenges may include the large size of the dataset, handling missing data, and ensuring confidentiality with sensitive information."
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html",
    "href": "posts/2025-03-17-blog-2/blog-2.html",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "",
    "text": "This project uses data from the study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù by Patrick Kline, Evan K. Rose, and Christopher Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nObjective: To detect whether disparate treatment in hiring‚Äîparticularly based on race, gender, and age‚Äîis concentrated within specific companies.\nDesign: A targeted randomized control trial where fictitious applications (varying by race, gender, and other resume characteristics) were submitted to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nScale: Over 84,000 applications were sent, enabling both firm-level and industry-level analysis of callback rates.\nContext: The data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis background provides important context on both the experimental design and the intended use of the data, highlighting potential challenges such as sample bias and variability across firms.\nIn this post, I describe the initial steps for loading and cleaning the dataset. I begin by reading in the cleaned data from an RDS file. The dataset contains various variables, including age_at_sub, month, year, and state, which I will explore to understand data quality and identify potential issues. Below is some sample R code I developed to generate diagnostic plots. I create a histogram to visualize the distribution of submissions throughout the months, faceted by year.\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html#data-background",
    "href": "posts/2025-03-17-blog-2/blog-2.html#data-background",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "",
    "text": "This project uses data from the study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù by Patrick Kline, Evan K. Rose, and Christopher Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nObjective: To detect whether disparate treatment in hiring‚Äîparticularly based on race, gender, and age‚Äîis concentrated within specific companies.\nDesign: A targeted randomized control trial where fictitious applications (varying by race, gender, and other resume characteristics) were submitted to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nScale: Over 84,000 applications were sent, enabling both firm-level and industry-level analysis of callback rates.\nContext: The data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis background provides important context on both the experimental design and the intended use of the data, highlighting potential challenges such as sample bias and variability across firms.\nIn this post, I describe the initial steps for loading and cleaning the dataset. I begin by reading in the cleaned data from an RDS file. The dataset contains various variables, including age_at_sub, month, year, and state, which I will explore to understand data quality and identify potential issues. Below is some sample R code I developed to generate diagnostic plots. I create a histogram to visualize the distribution of submissions throughout the months, faceted by year.\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-03-17-blog-2/blog-2.html#check-distribution-of-submission-month-throughout-years",
    "href": "posts/2025-03-17-blog-2/blog-2.html#check-distribution-of-submission-month-throughout-years",
    "title": "Blog 2: Data Loading, Cleaning, and Diagnostic Plots",
    "section": "Check distribution of submission month throughout years",
    "text": "Check distribution of submission month throughout years\n\nggplot(data, aes(x = month)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  \n  scale_x_continuous(\n    breaks = 1:12,\n    labels = month.abb\n  ) +\n  labs(\n    title = \"Distribution of Months\",\n    x = \"Month\",\n    y = \"Count\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45)) +\n  facet_grid(~year)\n\n\n\n\n\n\n\n\nThis plot shows sparse activity in early 2019, with submissions only appearing in a couple of months. In 2020, there is a notable increase, particularly in the latter half of the year. The highest volume of submissions occurs in early 2021, creating a distinct peak in the data. Overall, the distribution suggests that most of the data collection took place from late 2020 into the first months of 2021."
  },
  {
    "objectID": "posts/2025-04-22-blog-7/blog-7.html",
    "href": "posts/2025-04-22-blog-7/blog-7.html",
    "title": "Blog 7: Interactive Analysis",
    "section": "",
    "text": "Key objectives:\n\nHigh-level overview: Understand the names of the fake resumes and their callback rates.\nInteractive deep dive: Allow users to explore naming patterns and callback rates by race and gender.\n\n\n# Clear workspace\nrm(list = ls())\n\n\nInteractive Dashboard\nBelow is a self-contained Shiny app chunk that will render directly in your Quarto site using shinylive.\nInstructions:\n- üîπ Self-contained: All libraries and data loading happen within this chunk.\n- üîπ Small data: The RDS file is hosted on GitHub Pages for fast loading.\n\n# ```{shinylive-r} when ready to publish\nlibrary(shiny)\n\nWarning: package 'shiny' was built under R version 4.3.3\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\nlibrary(wordcloud2)\nlibrary(stringdist)\n\noptions(\"readr.edition\" = 1) # keep this to ensure you can download the data\ndata &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-teamate/dataset_for_shiny/cleaned_data.rds\")\n\n\n# Define UI for app\nui &lt;- fluidPage(\n  titlePanel(\"Interactive Name Analysis Dashboard\"),\n  sidebarLayout(\n    sidebarPanel(\n      h4(\"Word Cloud Settings\"),\n      selectInput(\"race_wc\", \"Select Race:\", choices = sort(unique(data$race)), selected = \"White\"),\n      selectInput(\"gender_wc\", \"Select Gender:\", choices = sort(unique(data$gender)), selected = unique(data$gender)[1])\n    ),\n    mainPanel(\n      wordcloud2Output(\"name_wc\", width = \"100%\", height = \"600px\"),\n      br(),\n      h4(\"Top Names by Callback Rate\"),\n      tableOutput(\"top_callbacks\")\n    )\n  )\n)\n\n# Define server logic required to draw --\nserver &lt;- function(input, output, session) {\n  filtered_wc &lt;- reactive({\n    req(input$race_wc, input$gender_wc)\n    data %&gt;% filter(race == input$race_wc, gender == input$gender_wc)\n  })\n\n  \n  output$name_wc &lt;- renderWordcloud2({\n    df &lt;- filtered_wc() %&gt;%\n      count(firstname) %&gt;%\n      arrange(desc(n)) %&gt;%\n      head(100)\n    wordcloud2(df, size = 1)\n  })\n\n\n  output$top_callbacks &lt;- renderTable({\n    df &lt;- filtered_wc() %&gt;%\n      group_by(firstname) %&gt;%\n      summarise(\n        callback_rate = mean(cb, na.rm = TRUE),\n        count = n()\n      ) %&gt;%\n      arrange(desc(callback_rate), desc(count)) %&gt;%\n      head(10)\n    df\n  }, rownames = FALSE)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nDeployment tips:\n1. Confirm this chunk runs locally as a standard R chunk.\n2. Place the RDS file in your scripts/ folder and push to GitHub.\n3. Update the read_rds() URL to point to your published scripts/ location.\n4. Change the chunk engine to shinylive-r and re-render the site.\n5. Adjust viewerHeight as needed to fit your page layout.\nThis interactive component complements the static analysis by letting readers examine names and callback patterns directly by subgroup."
  },
  {
    "objectID": "posts/2025-04-22-blog-8/blog-8.html",
    "href": "posts/2025-04-22-blog-8/blog-8.html",
    "title": "Blog 8: Progress So Far",
    "section": "",
    "text": "This figure shows mean contact rates by applicant first name, organized by race group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names.\n\n\nIn addition to the figure above, we will also include a table that summarizes the data used in the analysis. This table will provide an overview of the key variables, allowing readers to better understand the context of the analysis.\nAlso, we plan to include a regression table that summarizes the results of the regression analysis. This table will provide a more detailed look at the relationship between the variables and will help to support our conclusions.\nFinally, the visualization of the regression results will be included to provide a clear and concise representation of the findings. This visualization will help to highlight the key trends and patterns in the data, making it easier for readers to understand the implications of the analysis."
  },
  {
    "objectID": "posts/2025-04-22-blog-8/blog-8.html#continuing-exploratory-data-analysis",
    "href": "posts/2025-04-22-blog-8/blog-8.html#continuing-exploratory-data-analysis",
    "title": "Blog 8: Progress So Far",
    "section": "",
    "text": "This figure shows mean contact rates by applicant first name, organized by race group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names.\n\n\nIn addition to the figure above, we will also include a table that summarizes the data used in the analysis. This table will provide an overview of the key variables, allowing readers to better understand the context of the analysis.\nAlso, we plan to include a regression table that summarizes the results of the regression analysis. This table will provide a more detailed look at the relationship between the variables and will help to support our conclusions.\nFinally, the visualization of the regression results will be included to provide a clear and concise representation of the findings. This visualization will help to highlight the key trends and patterns in the data, making it easier for readers to understand the implications of the analysis."
  },
  {
    "objectID": "posts/2025-04-22-blog-8/blog-8.html#thesis",
    "href": "posts/2025-04-22-blog-8/blog-8.html#thesis",
    "title": "Blog 8: Progress So Far",
    "section": "Thesis",
    "text": "Thesis\n\nBackground: Taste-based discrimination is an economic model of labor market discrimination which argues that employers‚Äô prejudice or dislikes in an organisational culture rooted in prohibited grounds can have negative results in hiring minority workers, meaning that they can be said to have a taste for discrimination.\n\nTaste-based Discrimination in initial resume screening manifests in callback rates that vary systematically by race and gender of first names. By analyzing fictitious job applications in a randomized correspondence experiment, we can both verify and quantify these disparities."
  },
  {
    "objectID": "posts/2025-04-22-blog-8/blog-8.html#plan-to-polish-visualizations-and-tables",
    "href": "posts/2025-04-22-blog-8/blog-8.html#plan-to-polish-visualizations-and-tables",
    "title": "Blog 8: Progress So Far",
    "section": "Plan to polish visualizations and tables",
    "text": "Plan to polish visualizations and tables\nWe plan to use gtsummary tool to output summary tables and ggplot2 to create visualizations. The gtsummary package is a powerful tool for creating publication-ready summary tables in R, while ggplot2 is a widely used package for creating high-quality visualizations.\n\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\nsuppressPackageStartupMessages(library(lfe))    \nsuppressPackageStartupMessages(library(lmtest))\nsuppressPackageStartupMessages(library(sandwich)) \nsuppressPackageStartupMessages(library(multiwayvcov))\nsuppressPackageStartupMessages(library(here))\nsuppressPackageStartupMessages(library(gtsummary))\nsuppressPackageStartupMessages(library(htmltools))\nsuppressPackageStartupMessages(library(broom))\nsuppressPackageStartupMessages(library(stringr))\n\ndata &lt;- readRDS(here::here(\"dataset/cleaned_data.rds\"))"
  },
  {
    "objectID": "posts/2025-04-22-blog-8/blog-8.html#summary-statistics-table",
    "href": "posts/2025-04-22-blog-8/blog-8.html#summary-statistics-table",
    "title": "Blog 8: Progress So Far",
    "section": "Summary Statistics Table",
    "text": "Summary Statistics Table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nAll Firms - Black\nN = 9,1411\nAll Firms - White\nN = 9,1341\nBalanced - Black\nN = 32,6651\nBalanced - White\nN = 32,7031\n\n\n\n\nAny contact\n1,972 (22%)\n2,103 (23%)\n7,647 (23%)\n8,380 (26%)\n\n\nAny voicemail contact\n1,246 (14%)\n1,383 (15%)\n5,410 (17%)\n6,052 (19%)\n\n\nAny email contact\n256 (2.8%)\n263 (2.9%)\n1,357 (4.2%)\n1,414 (4.3%)\n\n\nAny text message contact\n470 (5.1%)\n457 (5.0%)\n880 (2.7%)\n914 (2.8%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "posts/2025-04-14-blog-6/blog-6.html",
    "href": "posts/2025-04-14-blog-6/blog-6.html",
    "title": "Blog 6: Wrapping Up the Analysis",
    "section": "",
    "text": "This post replicates the table 1 and 2 in the paper in R.\nNote: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\nsuppressPackageStartupMessages(library(lfe))    \nsuppressPackageStartupMessages(library(lmtest))\nsuppressPackageStartupMessages(library(sandwich)) \nsuppressPackageStartupMessages(library(multiwayvcov))\n\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")"
  },
  {
    "objectID": "posts/2025-04-14-blog-6/blog-6.html#data-background-and-context",
    "href": "posts/2025-04-14-blog-6/blog-6.html#data-background-and-context",
    "title": "Blog 6: Wrapping Up the Analysis",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html\n\nfor(k in 1:4) {\n  data[[paste0(\"region4_\", k)]] &lt;- as.integer(data$region4 == k)\n}\n\nfor(k in 1:5) {\n  data[[paste0(\"wave\", k)]] &lt;- as.integer(data$wave == k)\n}"
  },
  {
    "objectID": "posts/2025-04-07-blog-5/blog-5.html",
    "href": "posts/2025-04-07-blog-5/blog-5.html",
    "title": "Blog 5: Geographic Analysis of Experiment and Census Data",
    "section": "",
    "text": "This code continues the same procedure as the previous blog, focusing on the analysis of a combined state-by-year dataset.\nNote: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\nsuppressPackageStartupMessages(library(usmap))\n\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n‚Ä¢ `` -&gt; `...2`\n‚Ä¢ `` -&gt; `...3`\n‚Ä¢ `` -&gt; `...4`\n‚Ä¢ `` -&gt; `...5`\n‚Ä¢ `` -&gt; `...6`\n‚Ä¢ `` -&gt; `...7`\n\ncensus_data_2 &lt;- read_excel('dataset/nst-est2019-01.xlsx', skip = 3)\n\nNew names:\n‚Ä¢ `` -&gt; `...1`\n\n# for census_data_2 only keep year column 13 and row 6 onwards\ncensus_data_2 &lt;- census_data_2 %&gt;%\n  select(1, 13) %&gt;%\n  slice(6:56) \n\n# rename first column to states \ncolnames(census_data_2)[1] &lt;- \"states\"\n\n# delete . in front of state names\ncensus_data_2 &lt;- census_data_2 %&gt;% \n  filter(grepl(\"^\\\\.\", states)) %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states))"
  },
  {
    "objectID": "posts/2025-04-07-blog-5/blog-5.html#data-background-and-context",
    "href": "posts/2025-04-07-blog-5/blog-5.html#data-background-and-context",
    "title": "Blog 5: Geographic Analysis of Experiment and Census Data",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-31-blog-4/blog-4.html",
    "href": "posts/2025-03-31-blog-4/blog-4.html",
    "title": "Blog 4: Extended Statistical Modeling",
    "section": "",
    "text": "Note: Experiment data is from 2019-2021, while census data is from 2019-2024. The following code aggregate application level data to the state level and merge it with the census data to calculate the proportion of applications by state.\nThis exercise will help us understand the background of the data on a state-by-state basis and explore the relationship between callback rates and other variables at the state level.\nrm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(fixest))\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n‚Ä¢ `` -&gt; `...2`\n‚Ä¢ `` -&gt; `...3`\n‚Ä¢ `` -&gt; `...4`\n‚Ä¢ `` -&gt; `...5`\n‚Ä¢ `` -&gt; `...6`\n‚Ä¢ `` -&gt; `...7`\n\ncensus_data_2 &lt;- read_excel('dataset/nst-est2019-01.xlsx', skip = 3)\n\nNew names:\n‚Ä¢ `` -&gt; `...1`\n\n# for census_data_2 only keep year column 13 and row 6 onwards\ncensus_data_2 &lt;- census_data_2 %&gt;%\n  select(1, 13) %&gt;%\n  slice(6:56) \n\n# rename first column to states \ncolnames(census_data_2)[1] &lt;- \"states\"\n\n# delete . in front of state names\ncensus_data_2 &lt;- census_data_2 %&gt;% \n  filter(grepl(\"^\\\\.\", states)) %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states))"
  },
  {
    "objectID": "posts/2025-03-31-blog-4/blog-4.html#data-background-and-context",
    "href": "posts/2025-03-31-blog-4/blog-4.html#data-background-and-context",
    "title": "Blog 4: Extended Statistical Modeling",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html",
    "href": "posts/2025-03-24-blog-3/blog-3.html",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "",
    "text": "rm(list = ls())\n# hide warnings\noptions(warn = -1)\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(stargazer))\nsuppressPackageStartupMessages(library(readxl))\n\ndata &lt;- readRDS(\"dataset/cleaned_data.rds\")\ncensus_data &lt;- read_excel('dataset/NST-EST2024-POP.xlsx')\n\nNew names:\n‚Ä¢ `` -&gt; `...2`\n‚Ä¢ `` -&gt; `...3`\n‚Ä¢ `` -&gt; `...4`\n‚Ä¢ `` -&gt; `...5`\n‚Ä¢ `` -&gt; `...6`\n‚Ä¢ `` -&gt; `...7`"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#data-background-and-context",
    "href": "posts/2025-03-24-blog-3/blog-3.html#data-background-and-context",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Data Background and Context",
    "text": "Data Background and Context\nThe dataset originates from the landmark study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù (Kline, Rose, and Walters, 2022).\n\nResearch Questions: The study explores whether discrimination is endemic to particular firms, investigates firm-level heterogeneity in callback rates, and considers the potential impact of industry, geographic location, and other structural factors.\n\nThe census data was retrieved from the United States Census Bureau at this link: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#extended-exploratory-analysis-and-equity-considerations",
    "href": "posts/2025-03-24-blog-3/blog-3.html#extended-exploratory-analysis-and-equity-considerations",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Extended Exploratory Analysis and Equity Considerations",
    "text": "Extended Exploratory Analysis and Equity Considerations\nIn this update, I extend my analysis to delve deeper into the structure of the data and highlight important equity issues. By examining the distribution of submissions by state and comparing callback rates by race, the analysis aims to uncover potential systemic biases and inform further steps."
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-submissions-by-state",
    "href": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-submissions-by-state",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Check distribution of submissions by state",
    "text": "Check distribution of submissions by state\nThe following code creates a bar plot that orders states by the count of submissions. This visualization helps identify geographic patterns in the data, which may be related to regional hiring practices or other local factors.\n\ndata %&gt;%\n  count(state) %&gt;%\n  arrange(desc(n)) %&gt;% \n  ggplot(aes(y = reorder(state, n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribution of States (Ordered by Count)\",\n    y = \"State\",\n    x = \"Count\"\n  )"
  },
  {
    "objectID": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-population-by-state",
    "href": "posts/2025-03-24-blog-3/blog-3.html#check-distribution-of-population-by-state",
    "title": "Blog 3: Extended Analysis and Equity Considerations",
    "section": "Check distribution of population by state",
    "text": "Check distribution of population by state\nThe following code organizes data from the U.S. Census Bureau and creates a bar plot that orders states by their population in 2024. This visualization highlights the distribution of population density across states, providing a clear comparison to the research data. By aligning the population data with the research findings, the plot demonstrates a correlation between states with higher populations and the number of samples collected in those states.\n\ncolnames(census_data)[1] &lt;- \"states\"\n\ncensus_data &lt;- census_data %&gt;% \n  select(-2) %&gt;% \n  slice(-(1:3))\n\ncolnames(census_data)[2:6] &lt;- c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\")\n\ncensus_data &lt;- census_data %&gt;% filter(grepl(\"^\\\\.\", states))\n\ncensus_data &lt;- census_data %&gt;% \n  filter(states != \".Puerto Rico\") %&gt;%\n  mutate(states = gsub(\"^\\\\.\", \"\", states)) \n\ncensus_data %&gt;%\n  ggplot(aes(y = reorder(states, `2024`), x = `2024`)) +  # Use backticks for column names\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Population Distribution by State (2024)\",\n    y = \"State\",\n    x = \"Population\"\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMATE.\nThe members of this team are below."
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis is a course project for MA[46]15 Data Science with R at the Boston University. We thank Professor Daniel Sussman and TF Aislinn Sullivan for their guidance and support throughout the course. We also thank our classmates for their feedback. The content and assessments for this course have been modified as part of Boston University‚Äôs Designing Antiracist Curricula Fellowship.\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "How much does your identity matter in landing an interview?\nMedia coverage of this study by Kline, Rose, and Walters, 2022:\nNew York Times\nMarketplace\nHere & Now\nYoutube Channel: econimate\nThis comes from the file big_picture.qmd.\nIn today‚Äôs competitive job market, a candidate‚Äôs name can be an unexpected gatekeeper.\nResumes bearing names commonly associated with different racial or gender groups may receive different callback rates‚Äîeven when qualifications are identical.\nThat‚Äôs the hidden bias we set out to uncover.\n&gt; Note: Sacred Journey by Michael Reeder: An Art Piece that represents the journey of self-discovery and identity."
  },
  {
    "objectID": "big_picture.html#data",
    "href": "big_picture.html#data",
    "title": "Big Picture",
    "section": "Data",
    "text": "Data\nWe used data from the study ‚ÄúSystemic Discrimination Among Large U.S. Employers‚Äù by Kline, Rose, and Walters (2022). The study examines discrimination in hiring practices through a large-scale correspondence experiment. Key aspects of the study include:\n\nsending over 84,000 fictitious applications to over 100 Fortune 500 firms across multiple waves (including during the COVID pandemic).\nThe data is used to measure systemic discrimination, a term defined by patterns or practices with a broad impact on an industry or geographic area, and to provide actionable intelligence for policy enforcement (e.g., EEOC investigations).\n\nThis is an example of how a sample of resumes looks like: \n\nNote: sourced from Figure A1: Examples of applicant resumes in the Rose et al.¬†(2022) paper.\n\n\n\nExplore it yourself\nThe interactive below lets you select any racial group and gender to view:\n\nA word cloud of the top first names in that subgroup.\n\nA table of the top names ranked by callback rate.\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| eval: true\n#| standalone: true\n#| viewerHeight: 640\n# ```{shinylive-r} when ready to publish\nlibrary(shiny)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(wordcloud2)\nlibrary(stringdist)\n\noptions(\"readr.edition\" = 1) # keep this to ensure you can download the data\ndata &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-teamate/dataset_for_shiny/cleaned_data.rds\")\n\n\n# Define UI for app\nui &lt;- fluidPage(\n  titlePanel(\"Interactive Name Analysis Dashboard\"),\n  sidebarLayout(\n    sidebarPanel(\n      h4(\"Word Cloud Settings\"),\n      selectInput(\"race_wc\", \"Select Race:\", choices = sort(unique(data$race)), selected = \"White\"),\n      selectInput(\"gender_wc\", \"Select Gender:\", choices = sort(unique(data$gender)), selected = unique(data$gender)[1]),\n      br(),\n      h4(\"Top Names by Callback Rate\"),\n      tableOutput(\"top_callbacks\")\n    ),\n    mainPanel(\n      wordcloud2Output(\"name_wc\", width = \"100%\", height = \"600px\")\n    )\n  )\n)\n\n# Define server logic required to draw --\nserver &lt;- function(input, output, session) {\n  filtered_wc &lt;- reactive({\n    req(input$race_wc, input$gender_wc)\n    data %&gt;% filter(race == input$race_wc, gender == input$gender_wc)\n  })\n\n  \n  output$name_wc &lt;- renderWordcloud2({\n    df &lt;- filtered_wc() %&gt;%\n      count(firstname) %&gt;%\n      arrange(desc(n)) %&gt;%\n      head(100)\n    \n    set.seed(123)\n    wordcloud2(df, size = 1)\n  })\n\n\n  output$top_callbacks &lt;- renderTable({\n    df &lt;- filtered_wc() %&gt;%\n      group_by(firstname) %&gt;%\n      summarise(\n        callback_rate = mean(cb, na.rm = TRUE)#,\n        #count = n()\n      ) %&gt;%\n      arrange(desc(callback_rate), \n              #desc(count)\n              ) %&gt;%\n      head(10)\n    df\n  }, rownames = FALSE)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "big_picture.html#descriptive-evidence-by-applicants-first-name",
    "href": "big_picture.html#descriptive-evidence-by-applicants-first-name",
    "title": "Big Picture",
    "section": "Descriptive Evidence by Applicants First Name",
    "text": "Descriptive Evidence by Applicants First Name\n\nThis figure shows mean contact rates by applicant first name, organized by race group. The horizontal bars show race group mean contact rates. We can see that, on average, black names receive fewer 30-day callbacks than white names."
  }
]